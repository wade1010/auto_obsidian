# AI技术主题列表
# 用于批量生成和定时任务

# 深度学习基础
基础:
  - 神经网络基础
  - 反向传播算法
  - 激活函数详解
  - 损失函数比较
  - 优化器算法 (SGD, Adam, AdamW)
  - 正则化技术 (L1, L2, Dropout)
  - 批归一化 (Batch Normalization)
  - 梯度消失与梯度爆炸

# Transformer 架构
Transformer:
  - Transformer架构详解
  - 自注意力机制 (Self-Attention)
  - 多头注意力 (Multi-Head Attention)
  - 位置编码 (Positional Encoding)
  - Encoder-Decoder架构
  - BERT模型原理
  - GPT系列模型
  - RoPE位置编码
  - Flash Attention优化

# 大语言模型
LLM:
  - 大语言模型训练方法
  - 指令微调 (Instruction Tuning)
  - RLHF人类反馈强化学习
  - 对齐技术 (Alignment)
  - 提示工程 (Prompt Engineering)
  - CoT思维链
  - Few-shot Learning
  - 上下文学习 (In-Context Learning)

# 高效微调技术
微调技术:
  - LoRA低秩适应
  - QLoRA量化LoRA
  - P-Tuning提示微调
  - Prefix Tuning
  - Adapter适配器微调
  - 全参数微调 vs 参数高效微调
  - PEFT技术综述

# 多模态模型
多模态:
  - CLIP模型
  - Stable Diffusion原理
  - DALL-E系列
  - Vision Transformer (ViT)
  - BLIP多模态理解
  - LLaVA多模态对话
  - 图生文与文生图
  - 视频理解模型

# Agent与工具使用
Agent:
  - AI Agent架构
  - ReAct框架
  - Function Calling
  - Tool Use技术
  - 多Agent协作
  - AutoGPT原理
  - LangChain框架
  - 智能体规划能力

# RAG检索增强
RAG:
  - RAG检索增强生成
  - 向量数据库原理
  - Embedding模型
  - 混合检索 (Hybrid Search)
  - 重排序 (Reranking)
  - 知识图谱增强RAG
  - RAG评估方法

# 推理与部署
推理部署:
  - 模型量化技术 (INT8, FP16)
  - TensorRT优化
  - vLLM推理引擎
  - Flash Attention推理优化
  - 模型蒸馏
  - 剪枝技术
  - ONNX格式转换
  - 本地部署方案

# 训练技巧
训练技巧:
  - 数据增强方法
  - 课程学习
  - 混合精度训练
  - 分布式训练
  - 梯度累积
  - 学习率调度策略
  - Warmup技巧
  - 模型并行与数据并行

# 前沿技术
前沿:
  - Mamba状态空间模型
  - RWKV线性注意力
  - 混合专家模型 (MoE)
  - 长上下文技术
  - 记忆机制
  - 持续学习
  - 元学习
  - 神经符号AI
